import os 
import re
import json

def parse_label(answers):
    """
        Function to parse the actual answer given by the LLM. 

        :answer: list of answers generated by the model

        return: "entailment"/"contradiction" (string) 
    """

    # TODO add all possible terms if new 
    CONTRADICTION_TERMS = ['No', 'no', 'Contradiction.', 'there is no entailment', 'there is a contradiction', 'are contradictory', 'Negation of entailment']
    ENTAILMENT_TERMS = ['yes', 'Yes', 'there is an entailment', 'Entailment.', 'there is no contradiction', 'not contradictory', 'statement is supported', 'Not a contradiction', 'No contradiction', 'Non-Contradiction', 'does not conflict']

    # case sensitive ? 

    preds = []
    regexp = re.compile("No|no|Contradiction\.|there is no entailment|there is a contradiction|are contradictory|Negation of entailment|there is an entailment|Entailment\.|there is no contradiction|not contradictory|statement is supported|No contradiction|Non-Contradiction|does not conflict|yes|Yes")
    
    for i in answers:
        label = re.findall(regexp, i)
        if len(label) > 0:
            if label[0] in CONTRADICTION_TERMS:
                label = 'Contradiction'
            elif label[0] in ENTAILMENT_TERMS:
                label = 'Entailment'
            preds.append(label)
        else:
            preds.append("None")
    return preds 



RESULTS_FILE = '/XXX/results_muffin_flan_t5_1sccot.json'

def format_results(ctr_ids, preds):
    """
        Format the obtained predictions into the challenge's format and saves it in the file results.json.
    """
    content = {}

    for i in range(len(ctr_ids)):
        content[str(ctr_ids[i])] = {'Prediction': preds[i]}

    with open(RESULTS_FILE, 'w+') as f:
        f.write(json.dumps(content,indent=4))


"""
SUBMISSION FORMAT 
{

    "f17cb242-419d-4f5d-bfa4-41494ed5ac0e": {

        "Prediction": "Contradiction"

    }

}

"""
